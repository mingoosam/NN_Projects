{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c276e922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn #oop\n",
    "import torch.nn.functional as F #functions\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sklearn.metrics as sk_m\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "from IPython import embed\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import shutil\n",
    "\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb548782",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pytorch_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, data, transforms):\n",
    "        \n",
    "        super(Pytorch_Dataset, self).__init__()\n",
    "        \n",
    "        self.data = data\n",
    "        self.transforms = transforms\n",
    "        \n",
    "        self.create_dataset()\n",
    "        \n",
    "    def create_dataset(self):\n",
    "        \n",
    "        self.dataset = []\n",
    "        for sample, label in zip(self.data.samples, self.data.labels):\n",
    "            self.dataset.append([sample, label])\n",
    "\n",
    "    def transform_samples(self, samples):\n",
    "        \n",
    "        return self.transforms(samples)\n",
    "    \n",
    "    def transform_labels(self, labels):\n",
    "        \n",
    "        return torch.tensor(labels)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        # do transforms here :)\n",
    "        \n",
    "        sample, label = self.dataset[index]\n",
    "        \n",
    "        if(not(isinstance(sample, torch.Tensor))):\n",
    "            sample = self.transform_samples(sample).float()\n",
    "            \n",
    "        if(not(isinstance(label, torch.Tensor))):\n",
    "            label = self.transform_labels(label).float()\n",
    "        \n",
    "        return sample, label                            \n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64fe0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_folder(path):\n",
    "    \n",
    "    if(os.path.exists(path)):  # if the path already exits\n",
    "        #shutil.rmtree(path)  # remove the folder\n",
    "        return\n",
    "    else:\n",
    "        os.makedirs(path) # create the folder\n",
    "        \n",
    "class Dataset:\n",
    "    \n",
    "    def __init__(self, samples, labels):\n",
    "        self.samples = samples\n",
    "        self.labels = labels\n",
    "\n",
    "def one_hot_encode(all_labels, num_classes):\n",
    "    \n",
    "    ohv_labels = np.zeros((len(all_labels), num_classes))\n",
    "    \n",
    "    for i, current_label in enumerate(all_labels):\n",
    "        ohv_labels[i][current_label] = 1\n",
    "        \n",
    "    return ohv_labels\n",
    "    \n",
    "def get_dataset(which_dataset):\n",
    "    \n",
    "    if(which_dataset == \"mnist\".lower()):\n",
    "        \n",
    "        train = datasets.MNIST(root='../DATA', train=True, download=True)\n",
    "        test = datasets.MNIST(root='../DATA', train=False, download=True)\n",
    "        \n",
    "        train_idx = ((train.targets == 1) + (train.targets == 8)).nonzero().flatten()\n",
    "        test_idx = ((test.targets == 1) + (test.targets == 8)).nonzero().flatten()\n",
    "        \n",
    "        train.data, train.targets = train.data[train_idx], train.targets[train_idx]\n",
    "        test.data, test.targets = test.data[test_idx], test.targets[test_idx]\n",
    "        \n",
    "    if(which_dataset == \"fashion\".lower()):\n",
    "        \n",
    "        train = datasets.FashionMNIST(root='../DATA', train=True, download=True)\n",
    "        test = datasets.FashionMNIST(root='../DATA', train=False, download=True)\n",
    "    #embed()\n",
    "    train.data, test.data = train.data.numpy(), test.data.numpy()\n",
    "    train.targets, test.targets = train.targets.numpy(), test.targets.numpy()\n",
    "    \n",
    "    # use one hot encoding for MSE - turn off for torch.nn.CrossEnropy()\n",
    "    train.targets = one_hot_encode(train.targets, 10)\n",
    "    test.targets = one_hot_encode(test.targets, 10)\n",
    "    \n",
    "    train, test = Dataset(train.data, train.targets), Dataset(test.data, test.targets)\n",
    "    \n",
    "    sample_transforms = transforms.Compose([transforms.ToTensor(), \n",
    "                                           transforms.Normalize((0.5), (0.5))])\n",
    "    \n",
    "    train, test = Pytorch_Dataset(train, sample_transforms), Pytorch_Dataset(test, sample_transforms)\n",
    "    \n",
    "    # batch_size: how many samples at a time we pass to the model (generally 8 to 64). helps us generalize (each time it optimizes, optimizations that \"stick around\" tend to be general, rather than overfit, features). also helps training time\n",
    "    # shuffle: helps with generalization. don't want to learn all 1s, then all 2s, and so on.\n",
    "    train = torch.utils.data.DataLoader(train, batch_size=16, shuffle=True)\n",
    "    test = torch.utils.data.DataLoader(test, batch_size=1, shuffle=False)\n",
    "    #embed()                          \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6815483",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module): #inherits from nn.Module\n",
    "    \n",
    "    def __init__(self, lr, num_features, num_classes, loss, network, kernel_size, num_filters):\n",
    "        \n",
    "        super(Net, self).__init__() #initialize nn.Module\n",
    "        \n",
    "        self.alpha = lr\n",
    "        self.num_features = num_features\n",
    "        self.num_classes = num_classes\n",
    "        self.loss_choice = loss\n",
    "        self.net = network\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_filters = num_filters\n",
    "        #embed()\n",
    "        # MLP\n",
    "        if(self.net.lower() == \"mlp\"):\n",
    "            #embed()\n",
    "            self.network = torch.nn.Sequential(torch.nn.Linear(num_features, 512),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Linear(512, 256),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Linear(256, 128),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Linear(128, 64),\n",
    "                                               torch.nn.ReLU(),\n",
    "                                               torch.nn.Linear(64, num_classes))\n",
    "            \n",
    "#             self.network = torch.nn.Sequential(torch.nn.Linear(num_features, 64),\n",
    "#                                                torch.nn.ReLU(),\n",
    "#                                                torch.nn.Linear(64, 64),\n",
    "#                                                torch.nn.ReLU(),\n",
    "#                                                torch.nn.Linear(64, 32),\n",
    "#                                                torch.nn.ReLU(),\n",
    "#                                                torch.nn.Linear(32, 16),\n",
    "#                                                torch.nn.ReLU(),\n",
    "#                                                torch.nn.Linear(16, num_classes))\n",
    "\n",
    "        # CNN\n",
    "        if(self.network.lower() == \"cnn\"):\n",
    "\n",
    "            self.extract = torch.nn.Sequential(nn.Conv2d(in_channels = 1, out_channels = 2, kernel_size = kernel_size, stride = 1, padding = 1),\n",
    "                                               nn.ReLU(inplace=True),\n",
    "                                               nn.MaxPool2d(2),\n",
    "                                               nn.Conv2d(in_channels = 2, out_channels = 4, kernel_size = kernel_size, stride = 1, padding = 1),\n",
    "                                               nn.ReLU(inplace=True),\n",
    "                                               nn.MaxPool2d(2),\n",
    "#                                                nn.Conv2d(in_channels = 4, out_channels = 4, kernel_size = kernel_size, stride = 1, padding = 1),\n",
    "#                                                nn.ReLU(inplace=True),\n",
    "#                                                nn.MaxPool2d(2)\n",
    "                                                )\n",
    "            # in_channels = 1 for grayscale\n",
    "            # out_channels -> number of shared weights / features\n",
    "            # kernel size -> nxn kernel size\n",
    "            # stride -> how many pixels we move at a time\n",
    "            # padding -> adds 1 pixesl of zeros to each side of each dimension to maintain spatial dimensions for our kernel size\n",
    "            self.decimate = torch.nn.Sequential(nn.Linear(4 * (7*7), 12),\n",
    "                                                nn.ReLU(inplace=True),\n",
    "                                                nn.Linear(12, num_classes)\n",
    "                                                )\n",
    "        \n",
    "        # RBFN\n",
    "        \n",
    "        \n",
    "    def init_optimizer(self):\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr = self.alpha)\n",
    "        \n",
    "        #self.optimizer = torch.optim.SGD(self.parameters(), lr = self.alpha)\n",
    "\n",
    "    def objective(self, preds, labels): # this is the loss function\n",
    "        \n",
    "        #preds = F.log_softmax(preds, dim = 1) # dim 1: distribute across output layer of tensors. like np's axis param\n",
    "    \n",
    "        loss = torch.nn.MSELoss()\n",
    "        \n",
    "        return loss(preds, labels)\n",
    "    \n",
    "    def forward(self, x): # you can complicate the network in the forward() method.\n",
    "        \n",
    "        if(self.net.lower() == \"mlp\"):\n",
    "            x = self.network(x)\n",
    "        \n",
    "            return x\n",
    "        \n",
    "        if(self.net.lower() == 'cnn'):\n",
    "            features = self.extract(x)\n",
    "            features = features.view(features.size()[0], -1)\n",
    "            output = self.decimate(features)\n",
    "            \n",
    "            return output\n",
    "    \n",
    "def train(model, train_dataset, test_dataset, num_epochs = 50, rate = 5):\n",
    "    \n",
    "    training_loss, cf_matrices = [], []\n",
    "\n",
    "    model.init_optimizer()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        # Train network\n",
    "\n",
    "        epoch_loss = 0\n",
    "        \n",
    "        for i, data, in enumerate(tqdm(train_dataset, desc = \"Train Epoch %s\" % epoch)):\n",
    "            \n",
    "            sample, label = data\n",
    "            \n",
    "            # for CNN:\n",
    "            sample = sample.type('torch.FloatTensor')\n",
    "            label = label.type('torch.LongTensor')\n",
    "            \n",
    "            sample = sample.to(\"mps\")\n",
    "            label = label.to(\"mps\")\n",
    "            \n",
    "            # only for MLP:\n",
    "            #sample = sample.view(-1, 784)\n",
    "            \n",
    "            preds = model(sample)\n",
    "            #embed()\n",
    "            \n",
    "            loss = model.objective(preds, label.float())\n",
    "\n",
    "            epoch_loss = epoch_loss + loss.item()\n",
    "\n",
    "            model.optimizer.zero_grad() # zero the gradients after every batch\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            model.optimizer.step() # adjust the weights\n",
    "\n",
    "        epoch_loss = epoch_loss / (i + 1)\n",
    "        \n",
    "        print(epoch_loss)\n",
    "\n",
    "        training_loss.append(epoch_loss)\n",
    "\n",
    "        # Validate network\n",
    "        \n",
    "        if(epoch % rate == 0):\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            acc = 0\n",
    "            all_labels, all_preds = [], []\n",
    "            for i, (sample, label) in enumerate(tqdm(test_dataset, desc = \"Test Epoch %s\" % epoch)):\n",
    "                \n",
    "                #sample = sample.view(-1, 784)\n",
    "                \n",
    "                sample = sample.to(\"mps\")\n",
    "\n",
    "                logits = model(sample)\n",
    "                pred = torch.argmax(logits)\n",
    "\n",
    "                label = np.argmax(label.numpy())\n",
    "                \n",
    "                all_preds.append(int(pred.detach().cpu().numpy()))\n",
    "                all_labels.append(label)\n",
    "                \n",
    "                \n",
    "                if(pred == label):\n",
    "                    acc += 1\n",
    "                    \n",
    "            acc = acc / (i + 1)\n",
    "            \n",
    "            print(\"Valid Accuracy %s\" % acc)\n",
    "                \n",
    "            ##get metrics\n",
    "            training_metrics = {}\n",
    "            embed()\n",
    "            cf_matrix = sk_m.confusion_matrix(all_labels, all_preds)\n",
    "            \n",
    "            #epoch_accuracy = calculate_accuracy(np.asarray(all_preds), np.asarray(all_labels))\n",
    "\n",
    "            cf_matrices.append(cf_matrix)\n",
    "            print(f\"confusion matrix appended. epoch {epoch}\")\n",
    "            model.train()\n",
    "            \n",
    "        training_metrics = {}\n",
    "        training_metrics[\"labels\"] = all_labels\n",
    "        training_metrics[\"preds\"] = all_preds\n",
    "        training_metrics[\"mats\"] = cf_matrices\n",
    "            \n",
    "    return training_loss, training_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d1a003",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 6742, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 5851, 9: 0}\n",
      "{0: 0, 1: 1135, 2: 0, 3: 0, 4: 0, 5: 0, 6: 0, 7: 0, 8: 974, 9: 0}\n"
     ]
    }
   ],
   "source": [
    "which_dataset = \"mnist\" # \"mnist\" or \"fashion\"\n",
    "which_network = \"mlp\"\n",
    "\n",
    "loss_choice = \"mse\"\n",
    "\n",
    "batch_size = 16\n",
    "num_features = 784\n",
    "num_classes = 10\n",
    "\n",
    "alpha = 1e-4 \n",
    "\n",
    "kernel_size = 1\n",
    "num_filters = 8\n",
    "\n",
    "train_dataset, test_dataset = get_dataset(which_dataset)\n",
    "total = 0\n",
    "counter = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in train_dataset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter[(int(torch.nonzero(y)))] += 1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "new_counter = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "for data in test_dataset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        new_counter[(int(torch.nonzero(y)))] += 1\n",
    "\n",
    "print(new_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c335c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataloader.DataLoader"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef723c93",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_choice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwhich_network\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_filters\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmps\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m train_loss, train_metrics \u001b[38;5;241m=\u001b[39m train(model, train_dataset, test_dataset)\n",
      "Cell \u001b[0;32mIn[9], line 39\u001b[0m, in \u001b[0;36mNet.__init__\u001b[0;34m(self, lr, num_features, num_classes, loss, network, kernel_size, num_filters)\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(num_features, \u001b[38;5;241m512\u001b[39m),\n\u001b[1;32m     19\u001b[0m                                                torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     20\u001b[0m                                                torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m                                                torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m     26\u001b[0m                                                torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m, num_classes))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m#             self.network = torch.nn.Sequential(torch.nn.Linear(num_features, 64),\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m#                                                torch.nn.ReLU(),\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#                                                torch.nn.Linear(64, 64),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m         \u001b[38;5;66;03m# CNN\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcnn\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextract \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, out_channels \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, kernel_size \u001b[38;5;241m=\u001b[39m kernel_size, stride \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m     42\u001b[0m                                                nn\u001b[38;5;241m.\u001b[39mReLU(inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m),\n\u001b[1;32m     43\u001b[0m                                                nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#                                                nn.MaxPool2d(2)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m                                                 )\n\u001b[1;32m     51\u001b[0m             \u001b[38;5;66;03m# in_channels = 1 for grayscale\u001b[39;00m\n\u001b[1;32m     52\u001b[0m             \u001b[38;5;66;03m# out_channels -> number of shared weights / features\u001b[39;00m\n\u001b[1;32m     53\u001b[0m             \u001b[38;5;66;03m# kernel size -> nxn kernel size\u001b[39;00m\n\u001b[1;32m     54\u001b[0m             \u001b[38;5;66;03m# stride -> how many pixels we move at a time\u001b[39;00m\n\u001b[1;32m     55\u001b[0m             \u001b[38;5;66;03m# padding -> adds 1 pixesl of zeros to each side of each dimension to maintain spatial dimensions for our kernel size\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/dev/lib/python3.8/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "model = Net(alpha, num_features, num_classes, loss_choice, which_network, kernel_size, num_filters).to(\"mps\")\n",
    "\n",
    "train_loss, train_metrics = train(model, train_dataset, test_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04f96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_num = \"kernel_size_1\"\n",
    "\n",
    "results = {}\n",
    "results[\"loss\"] = train_loss\n",
    "results[\"validation\"] = train_metrics # 1 confusion matrix per validation run\n",
    "    \n",
    "path_save = f\"/Users/andyvarner/Documents/NN_Spring2023/project_1/results/{which_network.upper()}/{which_dataset}\"\n",
    "\n",
    "if(os.path.join(path_save)):\n",
    "    print(\"creating folder\")\n",
    "    create_folder(path_save)  \n",
    "\n",
    "title = \"%s.pkl\" % (str(exp_num).zfill(3))\n",
    "filename = os.path.join(path_save, title)\n",
    "\n",
    "pickle.dump(results, open(filename, \"wb\"))\n",
    "\n",
    "torch.save(model.state_dict(), \"kernel_size_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349a4089",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5f9e57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
